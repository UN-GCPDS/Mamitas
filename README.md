# Mamitas
Este repositorio contiene un modelo de segmentaciÃ³n para dermatomas podales basado en imÃ¡genes tÃ©rmicas. Su objetivo principal es proporcionar herramientas y recursos para la segmentaciÃ³n de regiones especÃ­ficas del pie, utilizando tÃ©cnicas de aprendizaje profundo.

## Contenido

El repositorio se organiza en los siguientes cuadernos Jupyter, divididos en dos grandes grupos de modelos:

### **ResUNet:**
- **resunet-mamitas-train:**  
  Cuaderno para entrenar el modelo ResUNet para segmentaciÃ³n de dermatomas podales.
- **resunet-mamitas-test:**  
  Cuaderno para realizar inferencia con el modelo ResUNet entrenado.

### **YOLOv11:**
- **yolov11-mamitas-train:**  
  Cuaderno para entrenar YOLOv11 para segmentaciÃ³n de dermatomas podales.
- **yolov11-mamitas-test:**  
  Cuaderno para realizar inferencia con el modelo YOLOv11 entrenado.

## Requisitos

Para ejecutar estos cuadernos se requiere:
- Python 3.10 o superior
- TensorFlow 2.15 o superior
- PyTorch (para YOLOv11)
- OpenCV
- Matplotlib
- NumPy
- Kaggle API
- Roboflow API (para descarga y preprocesamiento de datos)
- Ultralytics (para YOLOv11)

## CÃ³mo usar

### **Entrenamiento**
1. Clona este repositorio en tu mÃ¡quina local o directamente en Kaggle.
2. Configura tu entorno con las dependencias necesarias.
3. Organiza tus datos tÃ©rmicos en la estructura requerida (ver secciÃ³n **Estructura de Datos**).
4. Selecciona el cuaderno de entrenamiento correspondiente al modelo que deseas utilizar (ResUNet o YOLOv11).
5. Ejecuta el cuaderno. Los modelos entrenados se guardarÃ¡n automÃ¡ticamente en la carpeta `./models/`.

### **Inferencia**
1. Una vez entrenado el modelo o si decides utilizar uno preentrenado, abre el cuaderno de inferencia correspondiente.
2. AsegÃºrate de tener las imÃ¡genes de prueba organizadas en la carpeta correcta (para ResUNet: `./datasets/Mamitas/Test/images/`; para YOLOv11, se usarÃ¡ el archivo de configuraciÃ³n `data.yaml` generado durante el proceso de descarga).
3. Ejecuta el cuaderno para obtener los resultados de segmentaciÃ³n.

## Estructura de Datos

Los cuadernos esperan que los datos estÃ©n organizados de la siguiente manera:

```plaintext
datasets/ 
â””â”€â”€ Mamitas/
  â”œâ”€â”€ Train/
  â”‚ â”œâ”€â”€ images/
  â”‚ â””â”€â”€ masks/
  â”œâ”€â”€ Valid/
  â”‚ â”œâ”€â”€ images/
  â”‚ â””â”€â”€ masks/
  â”œâ”€â”€ Test/
  â”‚ â”œâ”€â”€ images/
  â”‚ â””â”€â”€ masks/
```

Para YOLOv11, la estructura es ligeramente diferente y se configura mediante el archivo `data.yaml` que se genera al descargar el dataset.

## Resultados Esperados

A continuaciÃ³n, se muestran algunas mÃ©tricas de rendimiento (ejemplo) que se han obtenido en el proyecto para la segmentaciÃ³n de dermatomas podales:

| Modelo              | Variante | Dice Coefficient | Jaccard Index | Sensitivity | Specificity | Precision (P) | Recall (R) | mAP50 | mAP50-95 |
|---------------------|----------|------------------|---------------|-------------|-------------|---------------|------------|-------|----------|
| **ResUNet**        | default   | 0.97410          | 0.95062       | 0.97275     | 0.97275     | -             | -          | -     | -        |
| **YOLOv11 (Seg)**  | segmentation | -             | -             | -           | -           | 0.983         | 1          | 0.99  | 0.99     |

Los cuadernos incluyen visualizaciones de los resultados de entrenamiento y ejemplos de inferencia. Los modelos entrenados se guardan en la carpeta `./models/` y los resultados de evaluaciÃ³n se almacenan en `./results/`.

## Contribuciones

Â¡Las contribuciones son bienvenidas! Si encuentras errores o tienes sugerencias para mejorar estos cuadernos, por favor abre un issue o envÃ­a una pull request.

## Licencia

Este proyecto se distribuye bajo la licencia BSD 2-Clause. Consulta el archivo LICENSE para mÃ¡s detalles.

Â¡Listo para segmentar dermatomas podales con tÃ©cnicas de aprendizaje profundo! ðŸ‘£ðŸ”¥

